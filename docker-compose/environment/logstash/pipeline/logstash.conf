input {
  beats {
    port => 5044
  }
}

filter {
  grok {
    match => {
      "message" => [
        "^\[%{WORD:log_level}\] %{TIMESTAMP_ISO8601:timestamp} \| %{DATA:request_id} \| %{GREEDYDATA:content}$",
        "^\[%{WORD:log_level}\] %{TIMESTAMP_ISO8601:timestamp} \| %{GREEDYDATA:content}$"
      ]
    }
    tag_on_failure => ["_grokparsefailure"]
    add_field => { "grok_matched" => "true" }
  }

  if [grok_matched] == "true" {
    if [log_level] == "GIN" {
      grok {
        match => { "content" => "%{DATA:request_id} \| %{NUMBER:status_code:int} \| %{DATA:duration} \| %{IP:client_ip} \| %{WORD:http_method} %{GREEDYDATA:request_path}" }
        tag_on_failure => ["_gin_parse_failure"]
      }
    } else if [log_level] == "INFO" {
      grok {
        match => { "content" => "record consume log: %{GREEDYDATA:info_message}" }
        tag_on_failure => ["_info_parse_failure"]
      }
    } else if [log_level] == "SYS" {
      # SYS 日志不需要进一步解析，直接使用 content 字段
    }
  }

  # 解码 UTF-8 字符
  ruby {
    code => "
      event.to_hash.each do |key, value|
        if value.is_a?(String)
          event.set(key, value.gsub(/\[0x([0-9a-f]{2})\]/) { $1.to_i(16).chr }.force_encoding('UTF-8'))
        end
      end
    "
  }

  date {
    match => [ "timestamp", "yyyy/MM/dd - HH:mm:ss" ]
    target => "@timestamp"
    remove_field => ["timestamp"]
  }

  mutate {
    remove_field => [ "ecs", "agent", "input", "grok_matched" ]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    user => "elastic"
    password => "YourElasticPassword"
    index => "filebeat-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}
